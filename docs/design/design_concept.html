<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>AudioReach Concepts and Terminology &mdash; AudioReach Documentation 1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css" />
      <link rel="stylesheet" type="text/css" href="../_static/audioreach.css" />

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/sphinx_highlight.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="AudioReach Engine" href="arspf_design.html" />
    <link rel="prev" title="AudioReach Architecture Overview" href="arch_overview.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            AudioReach Documentation
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../sdk_overview.html">AudioReach Project Overview</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">AudioReach Designs</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="arch_overview.html">AudioReach Architecture Overview</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">AudioReach Concepts and Terminology</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#introduction">Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="#use-case-to-audio-graph-mapping">Use Case to Audio Graph Mapping</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#graphs">Graphs</a></li>
<li class="toctree-l4"><a class="reference internal" href="#keys-and-values">Keys and Values</a></li>
<li class="toctree-l4"><a class="reference internal" href="#graph-key-vector-gkv">Graph Key Vector (GKV)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#use-case-to-calibration-data-mapping">Use Case to Calibration Data Mapping</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#calibration-key-vector-ckv">Calibration Key Vector (CKV)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-identification-and-configuration">Module Identification and Configuration</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#tag-key-vector-tkv">Tag Key Vector (TKV)</a></li>
<li class="toctree-l4"><a class="reference internal" href="#data-exchange-modes">Data Exchange Modes</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#data-driven-through-h2xml">Data Driven through H2XML</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="arspf_design.html">AudioReach Engine</a></li>
<li class="toctree-l2"><a class="reference internal" href="args_design.html">AudioReach Graph Services</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpr_design.html">Generic Packet Router</a></li>
<li class="toctree-l2"><a class="reference internal" href="lx_design.html">Linux Adaptation Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="arc_design.html">AudioReach Creator Design</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../api/index.html">AudioReach APIs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dev/index.html">AudioReach Developer Guides</a></li>
<li class="toctree-l1"><a class="reference internal" href="../platform/index.html">Platform Reference Guide</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">AudioReach Documentation</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="index.html">AudioReach Designs</a></li>
      <li class="breadcrumb-item active">AudioReach Concepts and Terminology</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/design/design_concept.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="audioreach-concepts-and-terminology">
<span id="design-concept"></span><h1>AudioReach Concepts and Terminology<a class="headerlink" href="#audioreach-concepts-and-terminology" title="Permalink to this heading"></a></h1>
<nav class="contents local" id="contents">
<ul class="simple">
<li><p><a class="reference internal" href="#introduction" id="id3">Introduction</a></p></li>
<li><p><a class="reference internal" href="#use-case-to-audio-graph-mapping" id="id4">Use Case to Audio Graph Mapping</a></p>
<ul>
<li><p><a class="reference internal" href="#graphs" id="id5">Graphs</a></p></li>
<li><p><a class="reference internal" href="#keys-and-values" id="id6">Keys and Values</a></p></li>
<li><p><a class="reference internal" href="#graph-key-vector-gkv" id="id7">Graph Key Vector (GKV)</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#use-case-to-calibration-data-mapping" id="id8">Use Case to Calibration Data Mapping</a></p>
<ul>
<li><p><a class="reference internal" href="#calibration-key-vector-ckv" id="id9">Calibration Key Vector (CKV)</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#module-identification-and-configuration" id="id10">Module Identification and Configuration</a></p>
<ul>
<li><p><a class="reference internal" href="#tag-key-vector-tkv" id="id11">Tag Key Vector (TKV)</a></p></li>
<li><p><a class="reference internal" href="#data-exchange-modes" id="id12">Data Exchange Modes</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#data-driven-through-h2xml" id="id13">Data Driven through H2XML</a></p></li>
</ul>
</nav>
<section id="introduction">
<h2><a class="toc-backref" href="#id3" role="doc-backlink">Introduction</a><a class="headerlink" href="#introduction" title="Permalink to this heading"></a></h2>
<p>Design and implementation of AudioReach software revolves around following core concepts and associated terminology. Before developing audio applications using AudioReach, it is important for developers to comprehend these concepts:</p>
<blockquote>
<div><ul class="simple">
<li><p>Audio graphs</p></li>
<li><p>Key vectors</p></li>
<li><p>Module identification and configuration</p></li>
<li><p>Use case to audio graph mapping</p></li>
<li><p>Use case to calibration data mapping</p></li>
<li><p>Data driven through H2XML</p></li>
</ul>
</div></blockquote>
<p>This document will be referring to the AudioReach Engine (or ARE), which is the signal processing framework for AudioReach. For more information on AudioReach Engine, please refer to the <a class="reference internal" href="arspf_design.html#arspf-design"><span class="std std-ref">AudioReach Engine</span></a> page.</p>
</section>
<section id="use-case-to-audio-graph-mapping">
<h2><a class="toc-backref" href="#id4" role="doc-backlink">Use Case to Audio Graph Mapping</a><a class="headerlink" href="#use-case-to-audio-graph-mapping" title="Permalink to this heading"></a></h2>
<p>In AudioReach, use cases are represented as audio graphs containing a series of interconnected audio modules from source end point(s) to sink end point(s).
The following sections will discuss the different components of audio graphs in AudioReach and how to configure various aspects of an audio use case, as well as how these concepts are presented in AudioReach Creator.</p>
<section id="graphs">
<h3><a class="toc-backref" href="#id5" role="doc-backlink">Graphs</a><a class="headerlink" href="#graphs" title="Permalink to this heading"></a></h3>
<ul>
<li><p>A <strong>graph</strong> is a logical representation of a group of one or more sub-graphs connected together in-order to realize a specific use-case. Data moves across this graph to realize the use-case.</p>
<blockquote>
<div><ul class="simple">
<li><p>The simplest graph could be one subgraph consisting of a single module.</p></li>
</ul>
</div></blockquote>
</li>
<li><p><strong>Subgraphs</strong> are a logical abstraction for a group of modules that are connected and manipulated as a single entity. They are used to independently control portions of a graph when switching between use cases.</p>
<blockquote>
<div><ul class="simple">
<li><p>The purpose of dividing a use case into subgraphs is to make graph management easier. It is not always necessary to change all modules in a graph when the use case changes or when a device switch happens. Subgraphs enable an update to apply to only a part of the graph.</p></li>
<li><p>Using subgraphs reduces the number of entries required to complete a full device tuning for all use cases.</p></li>
</ul>
</div></blockquote>
</li>
<li><p><strong>Modules</strong> are independent blocks in the DSP or software that accomplish some aspect of a use case. They are the smallest independent processing unit within the signal processing framework. In AudioReach, every function from endpoint to endpoint is represented as a module. Some examples of modules include hardware sources and sinks, software memory endpoints, and audio processing such as filtering, and data logging and metering.</p></li>
<li><p><strong>Containers</strong> are a unique concept of AudioReach Engine. They allow a system designer to group and execute audio processing modules together in a single software thread.</p></li>
</ul>
<p>More detailed information about each of the concepts above can be found in the <a class="reference internal" href="arspf_design.html#arspf-design"><span class="std std-ref">AudioReach Engine</span></a> page.</p>
<p>The figure below illustrates key constructs and composition of a typical audio playback use case graph consisting of multiple subgraphs. Inside each subgraph, there are multiple modules, all assigned with unique IDs (instance id), which can be grouped into one or multiple containers. Please note that container may not be associated with only one subgraph.</p>
<figure class="fig-center align-default" id="id1">
<span id="example-audiopb-graph"></span><a class="reference internal image-reference" href="../_images/graph_concept.png"><img alt="../_images/graph_concept.png" src="../_images/graph_concept.png" style="width: 1051.5px; height: 327.75px;" /></a>
<figcaption>
<p><span class="caption-text">Example Audio Playback Graph</span><a class="headerlink" href="#id1" title="Permalink to this image"></a></p>
</figcaption>
</figure>
<p>Breaking an audio graph into subgraphs enables the audio system designer to group audio processing modules into higher-level constructs such as stream-leg and device-leg. Then, the designer can develop middleware layer to
manage the audio use case and the sink/source endpoint in the form of stream and device. Endpoints can be a hardware base, such as I2S, or a software base, such as shared memory for exchanging audio sample between client
and AudioReach Engine. During a state transition, such as switching the audio output to a different sink endpoint, the middleware layer only needs to tear down device-leg subgraph while retaining stream-leg subgraph.
Then, the use case can resume by instantiating another device-leg subgraph for new sink endpoint and reattaching it to the stream-leg subgraph to form a new full graph.</p>
</section>
<section id="keys-and-values">
<h3><a class="toc-backref" href="#id6" role="doc-backlink">Keys and Values</a><a class="headerlink" href="#keys-and-values" title="Permalink to this heading"></a></h3>
<p>A <strong>key</strong> is an abstract entity containing several values that uniquely identify some aspect of an audio use case.</p>
<p>A <strong>key vector</strong> (KV) is a general term used to describe a set of key-values. Each KV may
contain one or more key-value pairs. By using different KVs, multiple use cases and
calibrations can be achieved. In AudioReach, there are three kinds of KVs:</p>
<ul class="simple">
<li><p><strong>Graph key vector (GKV)</strong> – Defines a use case. Key-values are applied to subgraphs within the use case. The graph or system designer associates a set of unique &lt;keys&gt; and &lt;values&gt; when creating a sub-graph from the ARC UI canvas.</p></li>
<li><p><strong>Tag Key Vector (TKV)</strong> – Also known as a Module Tag. Applied to individual modules that require parameter control at runtime. Each module tag may contain one or more keys, and these keys may be applied on a per-module basis in the form of a TKV.</p></li>
<li><p><strong>Calibration key vector (CKV)</strong> – Define various calibrations within a single use case (for example, sample rate or volume dependency). Key-Values are applied to individual modules.</p></li>
</ul>
<p><strong>Key-value pairs</strong> are the individual keys and associated values in the key vector. For example, sound device can be a key and the value can be headphone, speaker, or other sound device.</p>
<p>The full list of keys and values enabled in AudioReach can be found in the <strong>Audio Calibration Database</strong> (or ACDB) in the file <a class="reference external" href="https://github.com/AudioReach/audioreach-conf/blob/master/linux/kvh2xml.h">kvh2xml.h</a>.</p>
</section>
<section id="graph-key-vector-gkv">
<h3><a class="toc-backref" href="#id7" role="doc-backlink">Graph Key Vector (GKV)</a><a class="headerlink" href="#graph-key-vector-gkv" title="Permalink to this heading"></a></h3>
<p>A <strong>GKV</strong>, also known as a use case ID, is a vector of key-value pairs that uniquely identify
a whole graph. The key-value pairs are used to select a unique combination of
subgraphs to realize the full use case.</p>
<section id="gkv-example">
<h4>GKV example<a class="headerlink" href="#gkv-example" title="Permalink to this heading"></a></h4>
<p>Below is an example set of GKVs for a Low-Latency playback graph:</p>
<ul class="simple">
<li><p>[StreamRx: PCM_LL_Playback] [DeviceRX: Speaker] [Instance: Instance_1] [DevicePP_Rx: Audio_MBDRC]</p></li>
</ul>
<p>The GKVs are managed by the PAL layer (audioreach-pal) at runtime. When a new stream is opened, the requested stream type will be sent to the pal_stream_open
API. These stream types are mapped to the StreamRx key values. So when opening the new stream, PAL will assign the next available
instance of the desired stream type and map the correct instance key and value. The same is true for the Device type as well. For example, if the caller of pal_stream_open specifies the output
device as “Speaker”, PAL will map this to the corresponding Speaker GKV.</p>
<p>Note that changing the key value does not automatically change the topology. When
making customizations, care must be taken to ensure that key values match their
respective subgraph topologies.
Together, these four key-values make up the full GKV which is addressed from the
driver-side perspective.
However, from the system designer perspective, these key-values can be assigned
flexibly to subgraphs. Each subgraph has a SGKV that always consists of one or more of
the graph key-values. This allows the system designer to achieve potentially complex
subgraph configurations from a simple set of graph key-values.</p>
</section>
</section>
</section>
<section id="use-case-to-calibration-data-mapping">
<h2><a class="toc-backref" href="#id8" role="doc-backlink">Use Case to Calibration Data Mapping</a><a class="headerlink" href="#use-case-to-calibration-data-mapping" title="Permalink to this heading"></a></h2>
<p>Once a graph is loaded on ARE, the next step is to push the corresponding calibration for all the modules in the graph so modules can produce desired acoustic output for intended use cases.
Mapping of calibration data to use case is done by querying ACDB with the calibration handle in the form of key-vector (CKV) as depicted in figure - <a class="reference internal" href="#example-audiopb-graph"><span class="std std-ref">Example Audio Playback Graph</span></a>.</p>
<p>Typically, calibration data being applied is highly dependent on runtime parameters such as sample-rate, bitwidth, channels, gains, and etc. Hence, it is likely system designer would use these run-time parameters as keys.</p>
<section id="calibration-key-vector-ckv">
<h3><a class="toc-backref" href="#id9" role="doc-backlink">Calibration Key Vector (CKV)</a><a class="headerlink" href="#calibration-key-vector-ckv" title="Permalink to this heading"></a></h3>
<p>A <strong>CKV</strong> is assigned at a per-module level to realize specific calibrations for a use case.
Calibration keys enable multiple calibrations within a single subgraph. Each module in
the subgraph may be dependent on none, some, or all available CKVs depending on the
system designer’s choice. The system designer may also choose to include or exclude
groups of module parameters from CKV dependency.
For example, a use case may require different module tunings for different sample rates.
Using CKVs, the user can specify which modules and module parameters are samplerate dependent or agnostic. This simplifies the total number of calibration entries and
reduces unnecessary copying between calibrations.</p>
<p>When assigning multiple CKVs to a module, the number of calibration entries is n*m,
where n and m are the number of values used for each key. For example, if one key had
4 values, and another had 6 values, the total number of calibration entries would be 24 if
both were assigned to a single module.</p>
<section id="ckv-example">
<h4>CKV example<a class="headerlink" href="#ckv-example" title="Permalink to this heading"></a></h4>
<p>Consider the Device subgraph from the Low Latency playback use case (note: this is the Low Latency playback graph that is used for the RB3 Gen2 device).</p>
<figure class="fig-left align-default">
<a class="reference internal image-reference" href="../_images/ckv_subgraph.png"><img alt="../_images/ckv_subgraph.png" src="../_images/ckv_subgraph.png" style="width: 1564.0px; height: 393.55px;" /></a>
</figure>
<p>The CKVs used in this subgraph are visible as drop-down menus in the top bar of the
subgraph.</p>
<p>By selecting CKVs from the drop-down menus, the system designer or tuning engineer
may recall a specific calibration for the entire subgraph. This can affect multiple modules at a time or only one module.
In this case, setting a volume level will change the calibration for the Volume Control module.
Selecting the volume level will change the gain value for all channels.  For example, setting the volume calibration to
“Level_3” will increase the gain value by a specified amount in the Volume Control module, as seen in the below image:</p>
<figure class="fig-left align-default">
<a class="reference internal image-reference" href="../_images/volume_control_ckv.png"><img alt="../_images/volume_control_ckv.png" src="../_images/volume_control_ckv.png" style="width: 1227.3999999999999px; height: 883.15px;" /></a>
</figure>
<p>CKVs can be viewed or modified by using the Key Configurator.</p>
<figure class="fig-left align-default">
<a class="reference internal image-reference" href="../_images/ckv_config.png"><img alt="../_images/ckv_config.png" src="../_images/ckv_config.png" style="width: 732.6999999999999px; height: 657.9px;" /></a>
</figure>
<p>Parameters may be copied from one calibration to another using the batch copy
function.</p>
</section>
</section>
</section>
<section id="module-identification-and-configuration">
<h2><a class="toc-backref" href="#id10" role="doc-backlink">Module Identification and Configuration</a><a class="headerlink" href="#module-identification-and-configuration" title="Permalink to this heading"></a></h2>
<p>A usecase may require enable/disable/configure certain capability at runtime e.g controllable audio effects: equalizer, volume, and echo cancellation. This capability can be supported by one or multiple modules in the audio graph.
Different algorithm developers can develop modules supporting same capability but different configuration parameters. Audio system designer may select one module over the other for his/her product.</p>
<p>Since the module implementing this capability may be different across different subgraphs and software does not want to be hard coded to work with fixed set of modules, a mechanism to identify and configure these modules in a generic way is needed.
AudioReach architecture refers generic identification and configuration mechanism as “tagging”.</p>
<section id="tag-key-vector-tkv">
<h3><a class="toc-backref" href="#id11" role="doc-backlink">Tag Key Vector (TKV)</a><a class="headerlink" href="#tag-key-vector-tkv" title="Permalink to this heading"></a></h3>
<p>A module tag, or <strong>TKV</strong>, is an identifier set on a module to identify and set runtime controllable
parameters.</p>
<p>For example, an audio application may need to support turning echo cancellation on or off during run-time. To do this, the audio system designer can define a tag “echo cancellation”, and keys “ON” and “OFF”.
Then, this tag-key pair can be used on the EC module in the graph.</p>
<p>Then, when the echo cancellation needs to be enabled/disabled/configured, the software fetches the tagged module info and configuration parameters from the Audio Calibration Database by passing the tag and key.
This allows the software to address and package the configuration to desired module running on AudioReach Engine in a generic fashion during run-time.</p>
<p>In AudioReach architecture, commands and events exchanged with ARE are always packaged as depicted in the figure below.</p>
<figure class="fig-left align-default" id="id2">
<img alt="../_images/module_structure.png" src="../_images/module_structure.png" />
<figcaption>
<p><span class="caption-text">Module Parameter Structure</span><a class="headerlink" href="#id2" title="Permalink to this image"></a></p>
</figcaption>
</figure>
<p>This capability can be supported by one or multiple modules in the audio graph. Additionally, different algorithm developers can develop modules supporting the same capabilities but with different configuration parameters.</p>
<p>Each module tag may contain one or more keys, and these keys may be applied on a per-module basis as a TKV. Multiple TKVs may be applied to a module for different states.
Other module tags may not have key(s) associated. In this case, only the tag is applied to a module.</p>
<section id="tkv-example">
<h4>TKV example<a class="headerlink" href="#tkv-example" title="Permalink to this heading"></a></h4>
<p>Consider the Media Format Converter (or MFC) module, which is used to convert the media format of audio streams.
During an audio playback use case, the MFC can convert the media format of the audio clip to a configuration that is supported by the
device endpoint. For example, if an output stream has a 44.1K sample rate, but the backend device is configured to 48K, the MFC will
convert the output stream to 48K to match the output device. This is accomplished through the use of the tag pspd_mfc, which contains keys for sampling rate, bit width, and channels.
The source code that configures this tag can be found in the <a class="reference external" href="https://github.com/AudioReach/audioreach-graphmgr/blob/5a78c5df2b45db3c5f024fffb12a9a83a61af4ff/plugins/tinyalsa/test/agmplay.c#L455">configure_mfc</a>
function in the AGM test application agmplay.c. The definition of this tag is listed in the kvh2xml.h file below:</p>
<figure class="fig-left align-default">
<a class="reference internal image-reference" href="../_images/mfc_kvh2xml.png"><img alt="../_images/mfc_kvh2xml.png" src="../_images/mfc_kvh2xml.png" style="width: 645.0px; height: 309.0px;" /></a>
</figure>
<p>TKVs can be assigned to modules through the “Key Configurator” tab in AudioReach Creator. To view:</p>
<ol class="arabic simple">
<li><p>On the top bar, select “View” and then “Key Configurator.” A Key Configurator tab will appear on the right</p></li>
<li><p>Select a module in the graph view.</p></li>
<li><p>Select the Key Configurator Tab on the right.</p></li>
</ol>
<figure class="fig-left align-default">
<img alt="../_images/open_key_configurator.png" src="../_images/open_key_configurator.png" />
</figure>
<ol class="arabic simple" start="4">
<li><p>Select the Module Tag tab. The currently assigned tags for the module can be seen on the top (if empty, there are no tags assigned to the module):</p></li>
</ol>
<figure class="fig-left align-default">
<img alt="../_images/mfc_assigned_tags.png" src="../_images/mfc_assigned_tags.png" />
</figure>
<p>Each group of module parameters, (called parameter ID (PID)) may be controlled by
module tags. In the above example, the pspd_mfc tag is assigned with three TKVs: Sampling Rate, Bit Width, and Channels.
In the Module Tag tab, the user can add a new
tag with an additional set of supported TKVs by selecting “Start Graph Modification”, then selecting the plus button in the top right of the Module Tag tab.</p>
<p>Below shows an example of how to add a new pspd_mfc tag index, with updated sample rate, bit width, and channel values:</p>
<figure class="fig-left align-default">
<img alt="../_images/add_new_mfc_tag.png" src="../_images/add_new_mfc_tag.png" />
</figure>
<p>Once the tag values are added in the Key Configurator window, the new parameter values can be set for each module tag entry. Close the Key Configurator and
double-click on the module in the Graph View to open the Calibration Window.</p>
<p>Click Tag Data in the left sidebar to reveal the module tag calibration. Then click the Tag Indices drop-down to set parameters for each tag index. The newly added tag values can be seen here.
Now, tag indices can be selected based on the desired output media format.</p>
<figure class="fig-left align-default">
<img alt="../_images/mfc_calibration_window.png" src="../_images/mfc_calibration_window.png" />
</figure>
</section>
</section>
<section id="data-exchange-modes">
<h3><a class="toc-backref" href="#id12" role="doc-backlink">Data Exchange Modes</a><a class="headerlink" href="#data-exchange-modes" title="Permalink to this heading"></a></h3>
<p>There are different modes which calibration/configuration data can be applied on targeted module(s).
Choice of mode is based on whether module has the mode implemented in consideration of size of configuration data, available memory to hold the calibration data, or memory access requirement (Read-Only, Read-Write).
Refer to <a class="reference internal" href="arspf_design.html#spf-cal-config-mode"><span class="std std-ref">Calibration and configuration</span></a> to learn more about data change modes. Note that GSL does not support shared-persistent calibration at time of writing.</p>
</section>
</section>
<section id="data-driven-through-h2xml">
<h2><a class="toc-backref" href="#id13" role="doc-backlink">Data Driven through H2XML</a><a class="headerlink" href="#data-driven-through-h2xml" title="Permalink to this heading"></a></h2>
<p>H2XML (Header to XML) is a generic tool for generating XML files from annotated C header files. Grammar and syntax of the annotations are similar to Doxygen.
H2XML plays big part in enabling data-driven workflow. For example, audio algorithm developers can generate metadata (in form of XML files) of their processing module from module header files using H2XML and
import generated XML file into ACDB via ARC tool to incorporate and configure audio processing module in use case graph design.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="arch_overview.html" class="btn btn-neutral float-left" title="AudioReach Architecture Overview" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="arspf_design.html" class="btn btn-neutral float-right" title="AudioReach Engine" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, AudioReach.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>